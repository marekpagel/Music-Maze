<!DOCTYPE>
<html>
	<head>
		<title>Music Maze</title>
		<script type="text/javascript" src="lib/three.r73.js"></script>
		<script type="text/javascript" src="lib/THREEx.KeyboardState.js"></script>
		<script type="text/javascript" src="src/maze.js"></script>
		<script type="text/javascript" src="src/camera.js"></script>
		<script type="text/javascript">

			var renderer, scene, camera, maze, cameraControls, debugCameraControls, 
			    analyser, frequencyData, audioSrc, audioCtx, ambientLight, lastcolor = 0.45, isMuted = false, gainNode;

			function toRad(degree) {
				return Math.PI * 2 * degree / 360;
			}
		
			function onLoad() { 
				loadAudio("https://raw.githubusercontent.com/marekpagel/Music-Maze/master/music/sample1.ogg");
			}
			
			function draw() {
				requestAnimationFrame(draw);
				
				//cameraControls.move();
				debugCameraControls.move();
				analyser.getByteFrequencyData(frequencyData);
				var sum = 0;
				for (var i = 0; i < 128; i++) {
					sum += frequencyData[i];
				}
				ambientColor = sum / 128 / 255;
				// [0.5, 0.8] -> [0.1, 1]
				// approximation based on one sample song
				// right now aplification is quite useless
				aplifiedAmbientColor = (ambientColor-0.5)/(0.3) * 0.9 + 0.2
				var colordif = Math.abs(aplifiedAmbientColor - lastcolor);
				if ( colordif > 0.12) {
					ambientLight.color.setRGB(1, 1, 1);
				} else if ( colordif > 0.09) {
					ambientLight.color.setRGB(0.7, 0.7, 0.7);
				} else if (colordif > 0.05) {
					ambientLight.color.setRGB(0.3, 0.3, 0.3);
				}

				lastcolor = aplifiedAmbientColor;

				
				renderer.render(scene, camera);
			}

			function loadAudio(path) {
				audioCtx = new (window.AudioContext || window.webkitAudioContext)();
				var request = new XMLHttpRequest();
				request.open("GET", path, true);
				request.responseType = "arraybuffer";
				request.onload = function() {
					audioCtx.decodeAudioData(request.response, function(buffer) {
						initAudio(buffer);
					})
				}
				request.send();
			}

			function initAudio(buffer) {
				audioSrc = audioCtx.createBufferSource();
				audioSrc.buffer = buffer;

				analyser = audioCtx.createAnalyser();
				analyser.smoothingTimeConstant = 0;
				gainNode = audioCtx.createGain();

				audioSrc.connect(analyser);
				analyser.connect(gainNode);
				gainNode.connect(audioCtx.destination)

				frequencyData = new Uint8Array(analyser.frequencyBinCount);
				initScene();
			}

			function initScene() {
								var canvasContainer = document.getElementById('myCanvasContainer'); 
				var width = 800; 
				var height = 500;

				renderer = new THREE.WebGLRenderer(); 
				renderer.setSize(width, height);
				renderer.gammaInput = true;
				renderer.gammaOutput = true;
				canvasContainer.appendChild(renderer.domElement);
				
				scene = new THREE.Scene();

				ambientLight = new THREE.AmbientLight(0xffffff);
				ambientLight.position.set(1, 1, 1);
				scene.add(ambientLight);
				
				camera = new THREE.PerspectiveCamera(80, width / height, 1, 1000);
				camera.position.set(0,0,95);
				camera.up = new THREE.Vector3(0,1,0);
				
				debugCameraControls = DebugCamera(camera, new THREEx.KeyboardState());
				
				var textureLoader = new THREE.TextureLoader();
				textureLoader.crossOrigin = 'Anonymous';
	
				maze = Maze(scene, textureLoader);
				
				//maze.next([0,0,0],[0,0,0], [1/3, 1/3, 1/3]);
				
				// TODO choose next position at random
				//      then move camera to that position
				//      then figure out prob distribution for the 3 connectors (left, right, front)
				//      (based on some music analysis procedure)
				//      then pass that to maze.next(); and recurse
				// TODO probably should move this proc into draw();
				var positions = maze.next([0,0,0],[0,0,0], [1, 0, 0]);
				maze.next([-100,0,60],[0,Math.PI/2,0], [1, 0, 0]);
				// this is actually right wall, prob dist *should* be [0,1,0]
				maze.next([-40,0,80],[0,0,0], [1, 0, 0]);
				maze.next([-60,0,140],[0,-Math.PI/2,0], [0, 0, 0]);
				audioSrc.start(0);
				draw();


				cameraControls = PathCamera(camera);

				var move4 = function() { cameraControls.move([-135,0,140], 0); };
				var move3 = function() { cameraControls.move([-40,0,140], -Math.PI/2, move4); };
				var move2 = function() { cameraControls.move([-40,0,60], Math.PI/2, move3); };
				var move1 = function() { cameraControls.move([0,0,60], Math.PI/2, move2); };

				move1();
			}

			function mute() {
				if (isMuted) {
					gainNode.gain.value = 1;
					isMuted = false;
				} else {
					gainNode.gain.value = 0;
					isMuted = true;
				}

			}
		</script>
	</head>
	<body onload="onLoad()">
		<div id="myCanvasContainer" style="margin: auto;width:800px;"></div>
		<button onclick="mute()">mute</button>
	</body>
</html>
